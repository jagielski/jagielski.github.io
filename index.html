<!doctype html>
<html lang="en-US">
<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

  <link href="https://fonts.googleapis.com/css?family=Lora|Roboto:500" rel="stylesheet">
  <link href="styles.css" rel="stylesheet">

  <title>Matthew Jagielski</title>
</head>
<body>
  <div class="container mt-3">
    <div class="row">
      <div id="About Me" class="col-6">
      	<h1>Matthew Jagielski</h1>
      	Northeastern University
      	<br>
      	Graduate Student
      	<br>
      	Email: (my last name).m@northeastern.edu
      	<br>
        <a href="https://github.com/jagielski">Github</a>
        <br>
	<a href="https://twitter.com/mcjagielski">Twitter</a>
        <br>
	<a href="https://scholar.google.com/citations?user=_8rw_GMAAAAJ&hl=en">Google Scholar</a>
      </div>
      <div class="col-5 d-none d-sm-block">
        <img src="images/me.jpg" alt="me.jpg" height="300px" width="auto">
      </div>
    </div>
    <div class="row mt-3">
      <div class="col">
        <h6>About Me</h6>
        I am currently a fourth year PhD student advised by <a href="http://www.ccs.neu.edu/home/alina/">Alina Oprea</a> and <a href="https://cnitarot.github.io/">Cristina Nita-Rotaru</a>, working as a member of the Network and Distributed Systems Security Lab (<a href="https://nds2.ccs.neu.edu/">NDS2</a>).
        <br>
        <br>
        My research is broadly at the intersection between machine learning, security, and privacy. The goal of my research is to design training and deployment of machine learning that is secure from real world adversaries. I also study the design of machine learning algorithms that preserve the privacy of individuals in the training set. I rely on techniques drawn from machine learning, theoretical computer science, and security.
        <br>
        <br>
        During summer '19, I was at Google Brain Privacy and Security, working with Nicolas Papernot on model extraction attacks. In summer '18, I worked at DoS and Abuse at Google, using machine learning to protect Google Cloud customers from DoS attacks.
		<br>
        <br>
		In other news, I enjoy running, swimming, and biking. I'm also a retired <a href="https://www.youtube.com/watch?v=3lHG5ywn0P8">Super Smash Brothers tournament competitor</a>.
      </div>
    </div>
    <br>
    <div class="row mt-3">
      <div class="col">
        <h6>Selected Publications - see <a href="https://scholar.google.com/citations?user=_8rw_GMAAAAJ&hl=en">Google Scholar</a> for full list</h6>
        <ul>
		  <li>
			Auditing Differentially Private Machine Learning - How Private is Private SGD?
			<br>
			Matthew Jagielski, Paul Hand, Alina Oprea
			<br>
			Preliminary version - NeurIPS 2019 Workshop on Robust AI in Financial Services
			<br>
			<a href="https://arxiv.org/abs/2006.07709">[Paper]</a><a href="https://github.com/jagielski/auditing-dpsgd">[Code]</a>
		  </li>
		  <li>
			Subpopulation Data Poisoning Attacks
			<br>
			Matthew Jagielski, Paul Hand, Alina Oprea
			<br>
			Preliminary version - NeurIPS 2019 Workshop on Robust AI in Financial Services
			<br>
			<a href="papers/subpop_finance.pdf">[Paper]</a>
		  </li>
		  <li>
			High-Fidelity Extraction of Neural Network Models
			<br>
			Matthew Jagielski, Nicholas Carlini, David Berthelot, Alex Kurakin, and Nicolas Papernot
			<br>
			Preprint
			<br>
			<a href="https://arxiv.org/abs/1909.01838">[Paper]</a>
		  </li>
		<li>
            		Threat Detection for Collaborative Adaptive Cruise Control in Connected Cars
	          	<br>
        	    	Matthew Jagielski, Nicholas Jones, Chung-Wei Lin, Cristina Nita-Rotaru, and Shinichi Shiraishi
            		<br>
            		ACM WiSec 2018
            		<br>
            		<a href="https://dl.acm.org/citation.cfm?id=3212492">[Paper]</a>
          </li>
          <li>
            Manipulating Machine Learning: Poisoning Attacks and Countermeasures for Regression Learning
            <br>
            Matthew Jagielski, Alina Oprea, Chang Liu, Cristina Nita-Rotaru, and Bo Li
            <br>
            IEEE S&P (Oakland) 2018
            <br>
            <a href="https://github.com/jagielski/manip-ml">[Code]</a> <a href="https://arxiv.org/abs/1804.00308">[Paper]</a>
          </li>
        </ul>
      </div>
    </div>
  </div>
</body>
</html>

